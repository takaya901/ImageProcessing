{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Synthesize.ipynb","provenance":[{"file_id":"1dXEgbVoBkII7jYsv0R4OB0WLpI2-ff9z","timestamp":1554412652733}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\n/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n  return f(*args, **kwds)\n"}],"source":["import numpy as np\n","import glob\n","import h5py\n","\n","from keras.preprocessing.image import load_img, img_to_array"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"-xkTuj02uMxt"},"outputs":[],"source":["dataset_path = '/content/drive/My Drive/MachineLearning/Synthesize/dataset'\n","output_path = '/content/drive/My Drive/MachineLearning/Synthesize/output'"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","import h5py\n","import time\n","\n","import matplotlib.pylab as plt\n","import matplotlib.pyplot as plot\n","\n","import keras.backend as K\n","from keras.utils import generic_utils\n","from keras.optimizers import Adam, SGD\n","\n","from keras.models import Model\n","from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n","from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n","from keras.layers import Input, Concatenate\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.pooling import MaxPooling2D\n","import keras.backend as K\n","from keras.models import load_model\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"4Lrl0ezH4qKG"},"outputs":[],"source":["datasetpath = output_path + '/dataset.hdf5'\n","patch_size = 32\n","batch_size = 256\n","epoch = 200\n","loss_list = []"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"ur2Xzche4zy9"},"outputs":[],"source":["def normalization(X):\n","    return X / 127.5 - 1\n","\n","def load_data(datasetpath):\n","    with h5py.File(datasetpath, \"r\") as hf:\n","        X_full_train = hf[\"TrainWithoutTarget\"][:].astype(np.float32)\n","        X_full_train = normalization(X_full_train)\n","        X_sketch_train = hf[\"TrainWithTarget\"][:].astype(np.float32)\n","        X_sketch_train = normalization(X_sketch_train)\n","        X_full_val = hf[\"TestWithoutTarget\"][:].astype(np.float32)\n","        X_full_val = normalization(X_full_val)\n","        X_sketch_val = hf[\"TestWithTarget\"][:].astype(np.float32)\n","        X_sketch_val = normalization(X_sketch_val)\n","        return X_full_train, X_sketch_train, X_full_val, X_sketch_val"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"y6t8J0jm447v"},"outputs":[],"source":["def conv_block_unet(x, f, name, bn_axis, bn=True, strides=(2,2)):\n","    x = LeakyReLU(0.2)(x)\n","    x = Conv2D(f, (3,3), strides=strides, name=name, padding='same')(x)\n","    if bn: x = BatchNormalization(axis=bn_axis)(x)\n","    return x\n","\n","def up_conv_block_unet(x, x2, f, name, bn_axis, bn=True, dropout=False):\n","    x = Activation('relu')(x)\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(f, (3,3), name=name, padding='same')(x)\n","    if bn: x = BatchNormalization(axis=bn_axis)(x)\n","    if dropout: x = Dropout(0.5)(x)\n","    x = Concatenate(axis=bn_axis)([x, x2])\n","    return x"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"qWJldlLU45eo"},"outputs":[],"source":["def generator_unet_upsampling(img_shape, disc_img_shape, model_name=\"generator_unet_upsampling\"):\n","    filters_num = 64\n","    axis_num = -1\n","    channels_num = img_shape[-1]\n","    min_s = min(img_shape[:-1])\n","\n","    unet_input = Input(shape=img_shape, name=\"unet_input\")\n","\n","    conv_num = int(np.floor(np.log(min_s)/np.log(2)))\n","    list_filters_num = [filters_num*min(8, (2**i)) for i in range(conv_num)]\n","\n","    # Encoder\n","    first_conv = Conv2D(list_filters_num[0], (3,3), strides=(2,2), name='unet_conv2D_1', padding='same')(unet_input)\n","    list_encoder = [first_conv]\n","    for i, f in enumerate(list_filters_num[1:]):\n","        name = 'unet_conv2D_' + str(i+2)\n","        conv = conv_block_unet(list_encoder[-1], f, name, axis_num)\n","        list_encoder.append(conv)\n","\n","    # prepare decoder filters\n","    list_filters_num = list_filters_num[:-2][::-1]\n","    if len(list_filters_num) < conv_num-1:\n","        list_filters_num.append(filters_num)\n","\n","    # Decoder\n","    first_up_conv = up_conv_block_unet(list_encoder[-1], list_encoder[-2],\n","                        list_filters_num[0], \"unet_upconv2D_1\", axis_num, dropout=True)\n","    list_decoder = [first_up_conv]\n","    for i, f in enumerate(list_filters_num[1:]):\n","        name = \"unet_upconv2D_\" + str(i+2)\n","        if i<2:\n","            d = True\n","        else:\n","            d = False\n","        up_conv = up_conv_block_unet(list_decoder[-1], list_encoder[-(i+3)], f, name, axis_num, dropout=d)\n","        list_decoder.append(up_conv)\n","\n","    x = Activation('relu')(list_decoder[-1])\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(disc_img_shape[-1], (3,3), name=\"last_conv\", padding='same')(x)\n","    x = Activation('tanh')(x)\n","\n","    generator_unet = Model(inputs=[unet_input], outputs=[x])\n","    return generator_unet"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"ldiN9XOJ4-Lp"},"outputs":[],"source":["def DCGAN_discriminator(img_shape, disc_img_shape, patch_num, model_name='DCGAN_discriminator'):\n","    disc_raw_img_shape = (disc_img_shape[0], disc_img_shape[1], img_shape[-1])\n","    list_input = [Input(shape=disc_img_shape, name='disc_input_'+str(i)) for i in range(patch_num)]\n","    list_raw_input = [Input(shape=disc_raw_img_shape, name='disc_raw_input_'+str(i)) for i in range(patch_num)]\n","\n","    axis_num = -1\n","    filters_num = 64\n","    conv_num = int(np.floor(np.log(disc_img_shape[1])/np.log(2)))\n","    list_filters = [filters_num*min(8, (2**i)) for i in range(conv_num)]\n","\n","    # First Conv\n","    generated_patch_input = Input(shape=disc_img_shape, name='discriminator_input')\n","    xg = Conv2D(list_filters[0], (3,3), strides=(2,2), name='disc_conv2d_1', padding='same')(generated_patch_input)\n","    xg = BatchNormalization(axis=axis_num)(xg)\n","    xg = LeakyReLU(0.2)(xg)\n","\n","    # First Raw Conv\n","    raw_patch_input = Input(shape=disc_raw_img_shape, name='discriminator_raw_input')\n","    xr = Conv2D(list_filters[0], (3,3), strides=(2,2), name='raw_disc_conv2d_1', padding='same')(raw_patch_input)\n","    xr = BatchNormalization(axis=axis_num)(xr)\n","    xr = LeakyReLU(0.2)(xr)\n","\n","    # Next Conv\n","    for i, f in enumerate(list_filters[1:]):\n","        name = 'disc_conv2d_' + str(i+2)\n","        x = Concatenate(axis=axis_num)([xg, xr])\n","        x = Conv2D(f, (3,3), strides=(2,2), name=name, padding='same')(x)\n","        x = BatchNormalization(axis=axis_num)(x)\n","        x = LeakyReLU(0.2)(x)\n","\n","    x_flat = Flatten()(x)\n","    x = Dense(2, activation='softmax', name='disc_dense')(x_flat)\n","\n","    PatchGAN = Model(inputs=[generated_patch_input, raw_patch_input], outputs=[x], name='PatchGAN')\n","\n","    x = [PatchGAN([list_input[i], list_raw_input[i]]) for i in range(patch_num)]\n","\n","    if len(x)>1:\n","        x = Concatenate(axis=axis_num)(x)\n","    else:\n","        x = x[0]\n","\n","    x_out = Dense(2, activation='softmax', name='disc_output')(x)\n","\n","    discriminator_model = Model(inputs=(list_input+list_raw_input), outputs=[x_out], name=model_name)\n","\n","    return discriminator_model"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"K8sbdYzs5D1h"},"outputs":[],"source":["def DCGAN(generator, discriminator, img_shape, patch_size):\n","    raw_input = Input(shape=img_shape, name='DCGAN_input')\n","    genarated_image = generator(raw_input)\n","\n","    h, w = img_shape[:-1]\n","    ph, pw = patch_size, patch_size\n","\n","    list_row_idx = [(i*ph, (i+1)*ph) for i in range(h//ph)]\n","    list_col_idx = [(i*pw, (i+1)*pw) for i in range(w//pw)]\n","\n","    list_gen_patch = []\n","    list_raw_patch = []\n","    for row_idx in list_row_idx:\n","        for col_idx in list_col_idx:\n","            raw_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(raw_input)\n","            list_raw_patch.append(raw_patch)\n","            x_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(genarated_image)\n","            list_gen_patch.append(x_patch)\n","\n","    DCGAN_output = discriminator(list_gen_patch+list_raw_patch)\n","\n","    DCGAN = Model(inputs=[raw_input],\n","                  outputs=[genarated_image, DCGAN_output],\n","                  name='DCGAN')\n","\n","    return DCGAN"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"mHfsHWLL5GiI"},"outputs":[],"source":["def load_generator(img_shape, disc_img_shape):\n","    model = generator_unet_upsampling(img_shape, disc_img_shape)\n","    return model\n","\n","def load_DCGAN_discriminator(img_shape, disc_img_shape, patch_num):\n","    model = DCGAN_discriminator(img_shape, disc_img_shape, patch_num)\n","    return model\n","\n","def load_DCGAN(generator, discriminator, img_shape, patch_size):\n","    model = DCGAN(generator, discriminator, img_shape, patch_size)\n","    return model"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"h7DfII_85JUK"},"outputs":[],"source":["def l1_loss(y_true, y_pred):\n","    return K.sum(K.abs(y_pred - y_true), axis=-1)\n","\n","def inverse_normalization(X):\n","    return (X + 1.) / 2.\n","\n","def to3d(X):\n","    if X.shape[-1]==3: return X\n","    b = X.transpose(3,1,2,0)\n","    c = np.array([b[0],b[0],b[0]])\n","    return c.transpose(3,1,2,0)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"SU640WYv5MH-"},"outputs":[],"source":["def plot_generated_batch(X_proc, X_raw, generator_model, batch_size, suffix):\n","    X_gen = generator_model.predict(X_raw)\n","    X_raw = inverse_normalization(X_raw)\n","    X_proc = inverse_normalization(X_proc)\n","    X_gen = inverse_normalization(X_gen)\n","\n","    Xs = to3d(X_raw[:5])\n","    Xg = to3d(X_gen[:5])\n","    Xr = to3d(X_proc[:5])\n","    Xs = np.concatenate(Xs, axis=1)\n","    Xg = np.concatenate(Xg, axis=1)\n","    Xr = np.concatenate(Xr, axis=1)\n","    XX = np.concatenate((Xs,Xg,Xr), axis=0)\n","\n","    plt.imshow(XX)\n","    plt.axis('off')\n","    plt.savefig(output_path + '/current_batch_'+suffix+'.png')\n","    plt.clf()\n","    plt.close()"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"--pluGtL5PXy"},"outputs":[],"source":["def extract_patches(X, patch_size):\n","    list_X = []\n","    list_row_idx = [(i*patch_size, (i+1)*patch_size) for i in range(X.shape[1] // patch_size)]\n","    list_col_idx = [(i*patch_size, (i+1)*patch_size) for i in range(X.shape[2] // patch_size)]\n","    for row_idx in list_row_idx:\n","        for col_idx in list_col_idx:\n","            list_X.append(X[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])\n","    return list_X\n","\n","def get_disc_batch(procImage, rawImage, generator_model, batch_counter, patch_size):\n","    if batch_counter % 2 == 0:\n","        # produce an output\n","        X_disc = generator_model.predict(rawImage)\n","        y_disc = np.zeros((X_disc.shape[0], 2), dtype=np.uint8)\n","        y_disc[:, 0] = 1\n","    else:\n","        X_disc = procImage\n","        y_disc = np.zeros((X_disc.shape[0], 2), dtype=np.uint8)\n","\n","    X_disc = extract_patches(X_disc, patch_size)\n","    return X_disc, y_disc"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"iWQIBbQf5Rx6"},"outputs":[],"source":["def train():\n","    # load data\n","    rawImage, procImage, rawImage_val, procImage_val = load_data(datasetpath)\n","\n","    img_shape = rawImage.shape[-3:]\n","    patch_num = (img_shape[0] // patch_size) * (img_shape[1] // patch_size)\n","    disc_img_shape = (patch_size, patch_size, procImage.shape[-1])\n","\n","    # train\n","    opt_dcgan = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt_discriminator = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # load generator model\n","    generator_model = load_generator(img_shape, disc_img_shape)\n","    # load discriminator model\n","    discriminator_model = load_DCGAN_discriminator(img_shape, disc_img_shape, patch_num)\n","\n","    generator_model.compile(loss='mae', optimizer=opt_discriminator)\n","    discriminator_model.trainable = False\n","\n","    DCGAN_model = load_DCGAN(generator_model, discriminator_model, img_shape, patch_size)\n","\n","    loss = [l1_loss, 'binary_crossentropy']\n","    loss_weights = [1E1, 1]\n","    DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n","\n","    discriminator_model.trainable = True\n","    discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n","\n","    # start training\n","    print('start training')\n","    for e in range(epoch):\n","\n","        starttime = time.time()\n","        perm = np.random.permutation(rawImage.shape[0])\n","        X_procImage = procImage[perm]\n","        X_rawImage  = rawImage[perm]\n","        X_procImageIter = [X_procImage[i:i+batch_size] for i in range(0, rawImage.shape[0], batch_size)]\n","        X_rawImageIter  = [X_rawImage[i:i+batch_size] for i in range(0, rawImage.shape[0], batch_size)]\n","        b_it = 0\n","        progbar = generic_utils.Progbar(len(X_procImageIter)*batch_size)\n","        for (X_proc_batch, X_raw_batch) in zip(X_procImageIter, X_rawImageIter):\n","            b_it += 1\n","            X_disc, y_disc = get_disc_batch(X_proc_batch, X_raw_batch, generator_model, b_it, patch_size)\n","            raw_disc, _ = get_disc_batch(X_raw_batch, X_raw_batch, generator_model, 1, patch_size)\n","            x_disc = X_disc + raw_disc\n","            # update the discriminator\n","            disc_loss = discriminator_model.train_on_batch(x_disc, y_disc)\n","\n","            # create a batch to feed the generator model\n","            idx = np.random.choice(procImage.shape[0], batch_size)\n","            X_gen_target, X_gen = procImage[idx], rawImage[idx]\n","            y_gen = np.zeros((X_gen.shape[0], 2), dtype=np.uint8)\n","            y_gen[:, 1] = 1\n","\n","            # Freeze the discriminator\n","            discriminator_model.trainable = False\n","            gen_loss = DCGAN_model.train_on_batch(X_gen, [X_gen_target, y_gen])\n","            # Unfreeze the discriminator\n","            discriminator_model.trainable = True\n","\n","            progbar.add(batch_size, values=[\n","                (\"D logloss\", disc_loss),\n","                (\"G tot\", gen_loss[0]),\n","                (\"G L1\", gen_loss[1]),\n","                (\"G logloss\", gen_loss[2])\n","            ])\n","\n","            if b_it % (procImage.shape[0]//batch_size) == 0:\n","                loss_list.append(gen_loss[0])\n","                \n","            # save images for visualization\n","            if b_it % (procImage.shape[0]//batch_size//2) == 0 and e % 10 == 0:\n","                plot_generated_batch(X_proc_batch, X_raw_batch, generator_model, batch_size, \"training\"+str(e))\n","                idx = np.random.choice(procImage_val.shape[0], batch_size)\n","                X_gen_target, X_gen = procImage_val[idx], rawImage_val[idx]\n","                plot_generated_batch(X_gen_target, X_gen, generator_model, batch_size, \"validation\"+str(e))\n","                generator_model.save(output_path + '/gen_model.h5')\n","\n","        print(\"\")\n","        print('Epoch %s/%s, Time: %s' % (e + 1, epoch, time.time() - starttime))\n","        if (e+1) % 2 == 0:          \n","            height = np.array(range(e+1))\n","            plot.plot(height, loss_list)\n","            plot.xlabel(\"Epoch\")\n","            plot.ylabel(\"Loss\")\n","            plot.savefig(output_path + '/loss.png')\n","    \n","    height = np.array(range(epoch))\n","    plot.plot(height, loss_list)\n","    plot.xlabel(\"Epoch\")\n","    plot.ylabel(\"Loss\")\n","    plot.savefig(output_path + '/loss.png')\n","    plot.show()\n","        \n","    generator_model.save(output_path + '/gen_model.h5')\n","    \n","    from keras.models import load_model\n","\n","#     gen_model = load_model(output_path + '/gen_model.h5')\n","    img = load_img('1.jpg', target_size=(64,64))\n","    array = img_to_array(img)\n","    \n","    in_array = []\n","    in_array.append(array)\n","    in_array = np.array(in_array)    \n","    \n","    test = generator_model.predict(in_array)\n","    X_gen = inverse_normalization(test)\n","    Xg = to3d(X_gen)\n","    Xg = np.concatenate(Xg, axis=1)\n","\n","    plt.imshow(Xg)\n","    plt.axis('off')\n","    plt.savefig(output_path + '/predict.png')\n","    plt.clf()\n","    plt.close()"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":772},"colab_type":"code","executionInfo":{"elapsed":1624,"status":"error","timestamp":1549335875484,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/-7pQWKaSPG38/AAAAAAAAAAI/AAAAAAAAEYU/gr_8fD-d9ck/s64/photo.jpg","userId":"12325478836236099261"},"user_tz":-540},"id":"SCCEJlgz5YYZ","outputId":"a8ec394e-3080-4d10-df06-177cb55a1546"},"outputs":[{"ename":"OSError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-c5e3d8c72f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-a52cc73709f9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrawImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawImage_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocImage_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-7af6b832f023>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(datasetpath)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mX_full_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrainWithoutTarget\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_full_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/MachineLearning/Synthesize/output/dataset.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}],"source":["loss_list = []\n","train()"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"p_pQCqz-6Au4"},"outputs":[],"source":["def resume_train():\n","    # load data\n","    rawImage, procImage, rawImage_val, procImage_val = load_data(datasetpath)\n","\n","    img_shape = rawImage.shape[-3:]\n","    patch_num = (img_shape[0] // patch_size) * (img_shape[1] // patch_size)\n","    disc_img_shape = (patch_size, patch_size, procImage.shape[-1])\n","\n","    # train\n","    opt_dcgan = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","    opt_discriminator = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","    # load generator model\n","#     generator_model = load_generator(img_shape, disc_img_shape)\n","    generator_model = load_model(output_path + '/gen_model.h5')\n","    # load discriminator model\n","    discriminator_model = load_DCGAN_discriminator(img_shape, disc_img_shape, patch_num)\n","\n","#     generator_model.compile(loss='mae', optimizer=opt_discriminator)\n","    discriminator_model.trainable = False\n","\n","    DCGAN_model = load_DCGAN(generator_model, discriminator_model, img_shape, patch_size)\n","\n","    loss = [l1_loss, 'binary_crossentropy']\n","    loss_weights = [1E1, 1]\n","    DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n","\n","    discriminator_model.trainable = True\n","    discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n","\n","    # start training\n","    print('start training')\n","    for e in range(epoch):\n","\n","        starttime = time.time()\n","        perm = np.random.permutation(rawImage.shape[0])\n","        X_procImage = procImage[perm]\n","        X_rawImage  = rawImage[perm]\n","        X_procImageIter = [X_procImage[i:i+batch_size] for i in range(0, rawImage.shape[0], batch_size)]\n","        X_rawImageIter  = [X_rawImage[i:i+batch_size] for i in range(0, rawImage.shape[0], batch_size)]\n","        b_it = 0\n","        progbar = generic_utils.Progbar(len(X_procImageIter)*batch_size)\n","        for (X_proc_batch, X_raw_batch) in zip(X_procImageIter, X_rawImageIter):\n","            b_it += 1\n","            X_disc, y_disc = get_disc_batch(X_proc_batch, X_raw_batch, generator_model, b_it, patch_size)\n","            raw_disc, _ = get_disc_batch(X_raw_batch, X_raw_batch, generator_model, 1, patch_size)\n","            x_disc = X_disc + raw_disc\n","            # update the discriminator\n","            disc_loss = discriminator_model.train_on_batch(x_disc, y_disc)\n","\n","            # create a batch to feed the generator model\n","            idx = np.random.choice(procImage.shape[0], batch_size)\n","            X_gen_target, X_gen = procImage[idx], rawImage[idx]\n","            y_gen = np.zeros((X_gen.shape[0], 2), dtype=np.uint8)\n","            y_gen[:, 1] = 1\n","\n","            # Freeze the discriminator\n","            discriminator_model.trainable = False\n","            gen_loss = DCGAN_model.train_on_batch(X_gen, [X_gen_target, y_gen])\n","            # Unfreeze the discriminator\n","            discriminator_model.trainable = True\n","\n","            progbar.add(batch_size, values=[\n","                (\"D logloss\", disc_loss),\n","                (\"G tot\", gen_loss[0]),\n","                (\"G L1\", gen_loss[1]),\n","                (\"G logloss\", gen_loss[2])\n","            ])\n","\n","            if b_it % (procImage.shape[0]//batch_size) == 0:\n","                loss_list.append(gen_loss[0])\n","                \n","            # save images for visualization\n","            if b_it % (procImage.shape[0]//batch_size) == 0 and e % 10 == 0:\n","                plot_generated_batch(X_proc_batch, X_raw_batch, generator_model, batch_size, \"training\"+str(e))\n","                idx = np.random.choice(procImage_val.shape[0], batch_size)\n","                X_gen_target, X_gen = procImage_val[idx], rawImage_val[idx]\n","                plot_generated_batch(X_gen_target, X_gen, generator_model, batch_size, \"validation\"+str(e))\n","                generator_model.save(output_path + '/gen_model.h5')\n","\n","        print(\"\")\n","        print('Epoch %s/%s, Time: %s' % (e + 1, epoch, time.time() - starttime))\n","        if e % 100 == 0:          \n","            height = np.array(range(len(loss_list)))\n","            plot.plot(height, loss_list)\n","            plot.xlabel(\"Epoch\")\n","            plot.ylabel(\"Loss\")\n","            plot.savefig(output_path + '/loss.png')\n","    \n","    height = np.array(range(epoch))\n","    plot.plot(height, loss_list)\n","    plot.xlabel(\"Epoch\")\n","    plot.ylabel(\"Loss\")\n","    plot.savefig(output_path + '/loss.png')\n","    plot.show()\n","        \n","    generator_model.save(output_path + '/gen_model.h5')"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1428},"colab_type":"code","executionInfo":{"elapsed":600623,"status":"error","timestamp":1547612448434,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/-7pQWKaSPG38/AAAAAAAAAAI/AAAAAAAAEYU/gr_8fD-d9ck/s64/photo.jpg","userId":"12325478836236099261"},"user_tz":-540},"id":"3xrQgrd_wyHL","outputId":"c42becd5-184e-494c-bb38-36a150e033ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["start training\n","30208/30208 [==============================] - 171s 6ms/step - D logloss: 0.6043 - G tot: 1.4019 - G L1: 0.0193 - G logloss: 1.2088\n","\n","Epoch 1/200, Time: 172.95369625091553\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5821 - G tot: 1.5297 - G L1: 0.0203 - G logloss: 1.3263\n","\n","Epoch 2/200, Time: 145.3279149532318\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5765 - G tot: 1.5697 - G L1: 0.0242 - G logloss: 1.3279\n","\n","Epoch 3/200, Time: 144.03214836120605\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5404 - G tot: 1.4518 - G L1: 0.0401 - G logloss: 1.0506\n","\n","Epoch 4/200, Time: 143.98797082901\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5266 - G tot: 1.2672 - G L1: 0.0338 - G logloss: 0.9295\n","\n","Epoch 5/200, Time: 143.8042435646057\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5585 - G tot: 1.3878 - G L1: 0.0492 - G logloss: 0.8958\n","\n","Epoch 6/200, Time: 143.96231079101562\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5622 - G tot: 1.4092 - G L1: 0.0473 - G logloss: 0.9361\n","\n","Epoch 7/200, Time: 143.86122035980225\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5710 - G tot: 1.5594 - G L1: 0.0481 - G logloss: 1.0785\n","\n","Epoch 8/200, Time: 144.0174651145935\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5790 - G tot: 1.5917 - G L1: 0.0309 - G logloss: 1.2824\n","\n","Epoch 9/200, Time: 143.98493432998657\n","30208/30208 [==============================] - 143s 5ms/step - D logloss: 0.5728 - G tot: 1.5974 - G L1: 0.0264 - G logloss: 1.3338\n","\n","Epoch 10/200, Time: 143.92588233947754\n","30208/30208 [==============================] - 146s 5ms/step - D logloss: 0.5715 - G tot: 1.5907 - G L1: 0.0251 - G logloss: 1.3395\n","\n","Epoch 11/200, Time: 146.60058736801147\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5692 - G tot: 1.5961 - G L1: 0.0238 - G logloss: 1.3578\n","\n","Epoch 12/200, Time: 142.48987317085266\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5723 - G tot: 1.5874 - G L1: 0.0229 - G logloss: 1.3583\n","\n","Epoch 13/200, Time: 142.16473150253296\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5680 - G tot: 1.6057 - G L1: 0.0223 - G logloss: 1.3830\n","\n","Epoch 14/200, Time: 142.23379969596863\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5671 - G tot: 1.5973 - G L1: 0.0223 - G logloss: 1.3747\n","\n","Epoch 15/200, Time: 142.2259452342987\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5662 - G tot: 1.6051 - G L1: 0.0220 - G logloss: 1.3854\n","\n","Epoch 16/200, Time: 142.43204379081726\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5644 - G tot: 1.6148 - G L1: 0.0217 - G logloss: 1.3980\n","\n","Epoch 17/200, Time: 142.2921543121338\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5634 - G tot: 1.6246 - G L1: 0.0215 - G logloss: 1.4095\n","\n","Epoch 18/200, Time: 142.2923502922058\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5616 - G tot: 1.6363 - G L1: 0.0214 - G logloss: 1.4221\n","\n","Epoch 19/200, Time: 142.30378317832947\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5614 - G tot: 1.6333 - G L1: 0.0215 - G logloss: 1.4185\n","\n","Epoch 20/200, Time: 142.2775456905365\n","30208/30208 [==============================] - 145s 5ms/step - D logloss: 0.5622 - G tot: 1.6387 - G L1: 0.0214 - G logloss: 1.4248\n","\n","Epoch 21/200, Time: 145.58858132362366\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5607 - G tot: 1.6444 - G L1: 0.0215 - G logloss: 1.4296\n","\n","Epoch 22/200, Time: 142.4068946838379\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5590 - G tot: 1.6469 - G L1: 0.0216 - G logloss: 1.4310\n","\n","Epoch 23/200, Time: 142.36537313461304\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5590 - G tot: 1.6506 - G L1: 0.0219 - G logloss: 1.4321\n","\n","Epoch 24/200, Time: 142.38625955581665\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5564 - G tot: 1.6575 - G L1: 0.0223 - G logloss: 1.4346\n","\n","Epoch 25/200, Time: 142.3141577243805\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5558 - G tot: 1.6663 - G L1: 0.0218 - G logloss: 1.4479\n","\n","Epoch 26/200, Time: 142.28107380867004\n","30208/30208 [==============================] - 141s 5ms/step - D logloss: 0.5575 - G tot: 1.6629 - G L1: 0.0225 - G logloss: 1.4374\n","\n","Epoch 27/200, Time: 142.32940220832825\n"," 4096/30208 [===>..........................] - ETA: 2:02 - D logloss: 0.5605 - G tot: 1.6593 - G L1: 0.0230 - G logloss: 1.4295"]}],"source":["loss_list = []\n","resume_train()"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"McSGPDC2Um8O"},"outputs":[],"source":["from PIL import Image\n","\n","img = Image.open('current_batch_validation.png')\n","img_array = np.asarray(img)\n","plt.axis('off')\n","plt.imshow(img_array)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HzT26jorLbSk"},"source":["#学習済みモデルで予測"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}}},"colab_type":"code","executionInfo":{"elapsed":5760,"status":"ok","timestamp":1548415520262,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/-7pQWKaSPG38/AAAAAAAAAAI/AAAAAAAAEYU/gr_8fD-d9ck/s64/photo.jpg","userId":"12325478836236099261"},"user_tz":-540},"id":"3wWgcJfmVFcH","outputId":"97a73793-2606-408d-f0bb-496f276c81e8"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-4e39c38d-4138-48e1-8fd8-cdc6420abe03\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-4e39c38d-4138-48e1-8fd8-cdc6420abe03\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving 0.jpg to 0.jpg\n"]}],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":796},"colab_type":"code","executionInfo":{"elapsed":1230,"status":"error","timestamp":1548837456143,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/-7pQWKaSPG38/AAAAAAAAAAI/AAAAAAAAEYU/gr_8fD-d9ck/s64/photo.jpg","userId":"12325478836236099261"},"user_tz":-540},"id":"scfpc63ZCokY","outputId":"111d608b-dfac-46bd-893d-7d7fdf1b48bd"},"outputs":[{"ename":"OSError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-991926b1b37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/MachineLearning/Synthesize/Test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'gen_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/MachineLearning/Synthesize/Test/gen_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}],"source":["from PIL import Image\n","from keras.preprocessing.image import load_img, img_to_array, array_to_img, save_img\n","from keras.models import load_model\n","\n","test_path = '/content/drive/My Drive/MachineLearning/Synthesize/Test/'\n","gen_model = load_model(test_path + 'gen_model.h5')"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"_9LzFHHZoSN1"},"outputs":[],"source":["img = load_img(test_path + '0.jpg', target_size=(64,64))\n","array = img_to_array(img)\n","print(array)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"5ag9uKUBDkNe"},"outputs":[],"source":["in_array = []\n","in_array.append(array)\n","in_array = np.array(in_array)\n","print(in_array)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1057,"status":"ok","timestamp":1548483288403,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/-7pQWKaSPG38/AAAAAAAAAAI/AAAAAAAAEYU/gr_8fD-d9ck/s64/photo.jpg","userId":"12325478836236099261"},"user_tz":-540},"id":"tsJMXE-pDMzk","outputId":"163c7092-d082-4565-c9e0-15f46e51a609"},"outputs":[{"name":"stdout","output_type":"stream","text":["elapsed_time:0.017178058624267578[sec]\n"]}],"source":["start = time.time()\n","norm = normalization(in_array)\n","test = gen_model.predict(norm)\n","test = inverse_normalization(test)\n","elapsed_time = time.time() - start\n","print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n","# print(test)\n","Xg = to3d(test[:1])\n","Xg = np.concatenate(Xg, axis=1)\n","pred = array_to_img(Xg)\n","save_img(test_path + 'predict.jpg', pred)\n","\n","# plt.imshow(Xg)\n","# plt.axis('off')\n","# plt.savefig(test_path + 'predict.jpg')\n","# plt.clf()\n","# plt.close()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"colab_type":"code","executionInfo":{"elapsed":33921,"status":"ok","timestamp":1576563027380,"user":{"displayName":"Takaya Ogawa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC7UK56uZCALjDimUnhcgti-sJupGbAIBfaRlFj=s64","userId":"06596765289148417782"},"user_tz":-540},"id":"5cAyS2JnFpxH","outputId":"aec40354-9dd7-4838-851f-edd4e5eeb3a5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:350: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n","  warnings.warn('Error in loading the saved optimizer '\n"]},{"name":"stdout","output_type":"stream","text":["elapsed_time:9.228650093078613[sec]\n","elapsed_time:0.02676987648010254[sec]\n","elapsed_time:0.02577376365661621[sec]\n","elapsed_time:0.027028322219848633[sec]\n","elapsed_time:0.02607560157775879[sec]\n","elapsed_time:0.026736974716186523[sec]\n","elapsed_time:0.0263822078704834[sec]\n","elapsed_time:0.025943994522094727[sec]\n","elapsed_time:0.02462911605834961[sec]\n"]}],"source":["from PIL import Image\n","from keras.preprocessing.image import load_img, img_to_array, array_to_img, save_img\n","from keras.models import load_model\n","\n","test_path = '/content/drive/My Drive/Research/test/real/'\n","pred_path = test_path + 'predict/'\n","data_path = test_path + 'crop/'\n","gen_model = load_model( '/content/drive/My Drive/Research/test/real/gen_model.h5')\n","\n","for i in range(9):\n","    #load\n","    img = load_img(data_path + str(i) + '.jpg', target_size=(128,128))\n","    array = img_to_array(img)\n","    in_array = []\n","    in_array.append(array)\n","    in_array = np.array(in_array)\n","\n","    #predict\n","    start = time.time()\n","    norm = normalization(in_array)\n","    test = gen_model.predict(norm)\n","    test = inverse_normalization(test)\n","    elapsed_time = time.time() - start\n","    print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n","\n","    #save\n","    Xg = to3d(test[:1])\n","    Xg = np.concatenate(Xg, axis=1)\n","    pred = array_to_img(Xg)\n","    save_img(pred_path + str(i) + '.jpg', pred)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"Mw_EoYVIQvsF"},"outputs":[],"source":[]}]}